---
output:
    github_document:
    pandoc_args: --webtex
always_allow_html: true
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "imgs/",
  out.width = "100%"
)

knitr::opts_chunk$set(echo = TRUE)
```


<!-- badges: start -->
![forthebadge](https://img.shields.io/badge/GEMM-Building-orange)
![forthebadge](https://forthebadge.com/images/badges/built-with-science.svg)

<!-- badges: end -->

# AnÃ¡lise do Metagenoma total - Shotgun <img src="imgs/1.png" align="right" width = "120px"/>
**Autor: MsC. Kelly Hidalgo**

ğŸ‡§ğŸ‡· Pipeline para a montagem e anotaÃ§Ã£o funcional de metagenomas totais. Este pipeline contempla todas as etapas do processamento, desde a avaliaÃ§Ã£o da qualidade das sequÃªncias, trimagem, montagem, cÃ¡lculo da cobertura, prediÃ§Ã£o e anotaÃ§Ã£o funcional e taxonÃ´mica dos genes. 

> ğŸ‡ªğŸ‡¸Pipeline para montaje y anotaciÃ³n funcional de metagenomas totales. Este pipeline contempla todas las etapas del procesamiento, desde la evaluaciÃ³n de la calidad de las secuencias, *trimming*, montaje, cÃ¡lculo de la cobertura, predicciÃ³n y anotaciÃ³n funcional y taxonÃ³mica de genes. 

## Ferramientas bioinformÃ¡ticas

### InstalaÃ§Ã£o Anaconda

ğŸ‡§ğŸ‡· Ã‰ recomendÃ¡vel instalar Anaconda, pois Ã© a forma mais fÃ¡cil para instalar as ferramentas bioinformÃ¡ticas necessÃ¡rias pro desenvolvimento deste pipeline. Anaconda Ã© uma distribuiÃ§Ã£o livre e aberta das linguagens *Python* e *R*, utilizada na ciÃªncia de dados e bioinformÃ¡tica. As diferente versÃµes dos programas se administram mediante um sinstema de gestÃ£o chamado *conda*, o qual faz bastante simples instalar, rodar e atualizar programas. [Aqui](https://conda.io/projects/conda/en/latest/user-guide/install/index.html) se encontram as instruÃ§Ãµes para a instalaÃ§Ã£o de Anaconda. 

Depois de instalado, *Anaconda* e o gestor *Conda*, podram ser criados *ambientes virtuais* par a instalaÃ§Ã£o das diferentes ferramentas bioinformÃ¡tica que serÃ£o usadas. 

> ğŸ‡ªğŸ‡¸ Es recomendable instalar Anaconda, pues es la forma mÃ¡s fÃ¡cil para instalar las herramientas bioinformÃ¡ticas necesarias para el desarrollo de este pipeline. Anaconda es una distribuciÃ³n libre y abierta de los lenguajes *Python* y *R*, utilizada en ciencia de datos y bioinformÃ¡tica. Las diferentes versiones de los programas se administran mediante un sistema de gestiÃ³n llamado *conda*, el cual hace bastante sencillo instalar, correr y actualizar programas.  [Aqui](https://conda.io/projects/conda/en/latest/user-guide/install/index.html) se encuentran las instrucciones para la instalaciÃ³n de Anaconda.
>
> DespuÃ©s de instalado *Anaconda* y su gestor *Conda*, podran ser creados *ambientes virtuales* para la instalaciÃ³n de las diferentes herramientas bioinformÃ¡ticas que serÃ¡n usadas.

---
# I. MetagenÃ´mica

## 0. Organizando os dados

### 0.1. SequÃªncias

ğŸ‡§ğŸ‡· Em este tutorial serÃ£o usadas seis metagenomas exemplo para rodar todo o *pipeline*. Descarregue os [*datasets*]() usando o comando `wget`.

> ğŸ‡ªğŸ‡¸ En este tutorial serÃ¡n usados seis metagenomas ejemplo para correr todo el *pipeline*. Descargue los [*datasets*]() usando el comando `wget`.

**Arquivos**

* `sample1_1.fq.gz` e `sample1_2.fq.gz`: Amostra 1
* `sample2_1.fq.gz` e `sample2_2.fq.gz`: Amostra 2
* `sample3_1.fq.gz` e `sample3_2.fq.gz`: Amostra 3
* `sample4_1.fq.gz` e `sample4_2.fq.gz`: Amostra 4
* `sample5_1.fq.gz` e `sample5_2.fq.gz`: Amostra 5
* `sample6_1.fq.gz` e `sample6_2.fq.gz`: Amostra 6

A continuaÃ§Ã£o encontrarÃ¡ uma sÃ©rie de comandos para organizar adequadamente os diretÃ³rios com as amostras.

```
## Crie um diretÃ³rio raiz para todo o processo
mkdir metagenomica

## Entre al nuevo directorio
cd metagenomica/

## Crie um novo diretÃ³rio para colocar os dados brutos
mkdir 00.RawData

## Entre em 00.RawData
cd 00.RawData/
```
Use o comando `mv` para mover os arquivos atÃ© o diretÃ³rio `00.RawData/`. 

No final do processo de organizaÃ§Ã£o deve ver seus diretÃ³rios assim:
`ls 00.RawData/`

```
sample1_1.fq.gz   sample1_2.fq.gz   sample2_1.fq.gz   sample2_2.fq.gz   sample3_1.fq.gz   sample3_2.fq.gz   sample4_1.fq.gz   sample4_2.fq.gz   sample5_1.fq.gz   sample5_2.fq.gz   sample6_1.fq.gz   sample6_2.fq.gz
```

Ã‰ fortmente recomendado rodar os comandos desde o diretÃ³rio base, que neste caso Ã©: `metagenomica/`

## 1. Controle da Qualidade

## 1.1. AvaliaÃ§Ã£o da qualidade

ğŸ‡§ğŸ‡· Para a avaliaÃ§Ã£o da qualidade serÃ¡ usado o programa [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/) que Ã© uma ferramenta que permite observar graficamente a qualidade das sequencias de Illumina. 

> ğŸ‡ªğŸ‡¸ Para la evaluaciÃ³n de la calidad serÃ¡ usado el programa [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/) que es una herramienta que  permite observar graficamente la calidad de las secuencias de Illumina. 

### 1.1.1. InstalaÃ§Ã£o 

Las instruÃ§Ãµes para a instalaÃ§Ã£o usando conda se encontram [aqui](https://anaconda.org/bioconda/fastqc). No entanto neste tutorial tambÃ©m serÃ£o apresentados.

Como jÃ¡ foi explicado anteriormente, com conda Ã© possÃ­vel criar ambientes virtuais para instalar as ferramentas bioinformÃ¡ticas. O primeiro ambiente que serÃ¡ criado se chamarÃ¡ **QualityControl**, onde se instalaram os programas relacionados com esse processo.

> ğŸ‡ªğŸ‡¸ [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/) es una herramienta para evaluar graficamente la calidad de las secuencias de Illumina. 
>
> Las instrucciones para instalaciÃ³n usando conda se encuentran [aqui](https://anaconda.org/bioconda/fastqc). Sin embargo aqui en este tutorial tambiÃ©n serÃ¡n presentadas
>
> Como ya fue explicado anteriorimente, con conda es posible crear ambientes virutuales para instalar las herramientas bioinformÃ¡ticas. El primer ambiente que serÃ¡ creado se llamarÃ¡ **QualityControl**, donde se instalaran los programas relacionados con este proceso.

```
conda create -n QualityControl
```
ğŸ‡§ğŸ‡· Durante o processo, o sistema perguntarÃ¡ se deseja proceder com a creaÃ§Ã£o do ambiente, com as opÃ§Ãµes y/n (sim ou nÃ£o). Escreva `y` e depois disso o ambiente virutal estarÃ¡ criado.

Para instalar as ferramentas dentro do ambiente anteriormente criado, Ã© necessÃ¡rio ativÃ¡-lo.

> ğŸ‡ªğŸ‡¸ Durante el proceso, el sistema preguntarÃ¡ sÃ­ desea proceder con la creaciÃ³n del ambiente, con las opciones y/n (si o no). Escriba `y` y despuÃ©s de eso el ambiente virtual estarÃ¡ creado.
>
> Para instalar las herramientas dentro del ambiente anteriormente creado, es necesario activarlo

```
conda activate QualityControl
```
ğŸ‡§ğŸ‡· O ambiente estarÃ¡ ativo quando o nome se encontre ao comeÃ§o da linha do comando, asssim: `(QualityControl) user@server:~/$`.
Posteriormente se procede Ã  instalaÃ§Ã£o do programa:

> ğŸ‡ªğŸ‡¸ El ambiente estarÃ¡ activo cuando el nombre de Ã©ste se encuentra en el comienzo de la linea de comando, asÃ­: `(QualityControl) user@server:~/$`.
> 
> Posteriormente se procede a la instalaciÃ³n del programa:

```
conda install -c bioconda fastqc
```

### 1.1.2. Uso

ğŸ‡§ğŸ‡· A primeira etapa do processo Ã© a avaliaÃ§Ã£o da qualidade das sequÃªncias cortas (Illumina paired end) usando *FastQC*, com o objetivo de determianr se Ã© necessÃ¡rio trimar ou filtrar as sequÃªncias da baixa qualidade para nos prÃ³ximos pasos. 

Esta etapa Ã© para identificar principalmente as sequÃªncias *outlier* com baixa qualidade ($Q<20$)

Ative o ambiente `QualityControl`:

> ğŸ‡ªğŸ‡¸ La primera etapa del proceso es la evaluaciÃ³n de la calidad de las secuencias cortas (Illumina paired end) usando *FastQC*, con el objetivo de determinar sÃ­ es necesario trimar o filtrar las secuencias de baja calidad en los prÃ³ximos pasos. 
>
> Ã‰sta etapa es para identificar principalmente las secuencias *outlier* con baja calidad ($Q<20$).
>
> Active el ambiente `QualityControl`:

```
conda activate QualityControl

## Onde vc estÃ¡?
pwd
```

ğŸ‡§ğŸ‡· Deve etsar em `~/metagenomica/`.. Se esse nÃ£o Ã© o resultado del comando `pwd`, use o comando `cd` para chegar no diretÃ³rio desejado.

> ğŸ‡ªğŸ‡¸ Debe estar em `~/metagenomica/`. Si ese no es el resultado del comando `pwd`, use el comando `cd` para llegar en el directorio base.

Execute  **FastQC**:
```
## Crie um directÃ³rio para salvar o output do FastQC
mkdir 01.FastqcReports
## Run usando 10 threads
fastqc -t 10 00.RawData/* -o 01.FastqcReports/
```

**Sintaxe**
`fastqc [opÃ§Ãµes] input -o output`

ğŸ‡§ğŸ‡· O comando `fastqc` tem vÃ¡rias opÃ§Ãµes ou parÃ¢metros, entre eles, escolher o nÃºmero de nÃºcleos da mÃ¡quina para rodar a anÃ¡lise, para este exemplo `-t 10`. O input Ã© o diretÃ³rio que contem as sequÃªncias `00.RawData/*`, o `*` indica ao sistema que pode analisar todos os arquivos que estÃ£o dentro desse diretÃ³rio. O output, indicado pelo parÃ¢mtero `-o`, Ã© o diretÃ³rio onde se deseja que sejam guardados os resultados da anÃ¡lise. A continuaÃ§Ã£o se encontram uma explicaÃ§Ã£o detalhada de cada output gerado.

> ğŸ‡ªğŸ‡¸ El comando `fastqc` tiene varias opciones o parametros, entre ellas, escoger el nÃºmero de nÃºcleos de la mÃ¡quina para correr el anÃ¡lisis, para este caso `-t 10`. El input es el directorio que contiene las secuencias `00.RawData/*`, el `*` indica al sistema que puede analizar todos los archivos que estÃ¡n dentro de ese directorio. El output, indicado por el parametro `-o`, es el directorio donde se desea que sean guardados los resultados del anÃ¡lisis. A continuaciÃ³n se encuentra una explicaciÃ³n detallada de cada output generado.

**Outputs**

ğŸ‡§ğŸ‡· 

* Reportes html `.html`: Aqui Ã© possÃ­vel ver toda informaÃ§Ã£o de qualidade graficamente. 

* Zip files `.zip`: Aqui se encontram cada um dos grÃ¡ficos de maneira separada. **IGNORE**

Descaregue os arquivos `html` e explore no seu *web browser*. 

Observe as estatÃ­sticas bÃ¡sicas que se encontram na primeira tabela. AlÃ­, vocÃª pode saber quantas sequÃªncias tem, o tamanho e o %GC. O grÃ¡fico mais importante para saber a quealidade das leituras, Ã© o primeiro, *Per base sequence quality*. Este grÃ¡fico Ã© um boxplot com a distribuiÃ§Ã£o dos valores de qualidade *Phred Score* (eje y) em cada um dos nucleotÃ­deos das leituras (eje x). Se consideram sequÃªncias de excelente qualidade quando o $Phred Score > 30$. Ã‰ norla que o pair 2 apresente uma qualidade um pouco inferior ao pair 1.

> ğŸ‡ªğŸ‡¸ Observe las estadÃ­sticas bÃ¡sicas que se encuentran en la primera tabla. AllÃ­, ud puede saber cuantas secuencias tiene, el tamaÃ±o y el %GC. El grÃ¡fico mÃ¡s importante para saber la calidad de las lecturas es el primero, *Per base sequence quality*. Este grÃ¡fico es un boxblot con la distribuciÃ³n de los valores de calidad *Phred Score* (eje y) en cada uno de los nucleÃ³tidos de las lecturas (eje x). Se consideran secuencias de excelente calidad cuando el $Phred Score > 30$. Es normal que el pair 2 presente una calidad un poco inferior al pair 1. 


### 1.2. Trimagem

> ğŸ‡ªğŸ‡¸ 1.2 DepuraciÃ³n


ğŸ‡§ğŸ‡· [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) Ã© um programa pra filtrar (remover) leituras ou *reads* curtas de baixa qualidade.

Trimmomatic tem vÃ¡rios parÃ¢metros que podem ser considerados para filtrar leituras com baixa qualidade. No presente tutorial usaremos alguns deles. Se quiser saber que otros parÃ¢metros e como funciona cada um deles, consulte o [manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).


> ğŸ‡ªğŸ‡¸ [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) es un programa para filtrar (remover) lecturas o *reads* cortas de baja calidad.
>
> Trimmomatic tiene vÃ¡rios parametros que pueden ser considerados para filtrar lecturas con baja calidad. Aqui usaremos algunos. Si quiere saber que otros parametros y como funciona cada uno de ellos, consulte el [manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).

### 1.2.1. InstalaÃ§Ã£o 

ğŸ‡§ğŸ‡· Como se trata de uma ferramenta que participa dentro do processo de control de qualidade, serÃ¡ instalada dentro do ambiente virtual **QualityControl**.

> Como se trata de una herramienta que participa dentro del proceso de control de calidad, serÃ¡ instalada dentro del ambiente virtual **QualityControl**

```
# Si no estÃ¡ activado el ambiente
conda activate QualityControl

# Instale Trimmomatic
conda install -c bioconda trimmomatic
```

### 1.2.2. Uso

ğŸ‡§ğŸ‡· Segundo foi avaliado no controle de qualidade, pode ser necessÃ¡rio filtrar algumas leituras com qualidade baixa.

O programa Trimmomatic tem vÃ¡rios parÃ¢metros que podem ser considerados para filtrar reads com baixa qualidade. Aqui usaremos alguns. Se quer saber que outros parÃ¢metros e como funciona cada um deles, consulte o [manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).

Para os dados aqui analizados se usara a seguinte linha de comando:

> ğŸ‡ªğŸ‡¸ SegÃºn fue evaluado en el control de calidad, puede ser necesario filtrar algunas lecturas con calidad baja.
>
> El programa Trimmomatic tiene vÃ¡rios parametros que pueden ser considerados para filtrar lecturas con baja calidad. Aqui usaremos algunos. Si quiere saber que otros parametros y como funciona cada uno de ellos, consulte el [manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).
> 
> Para los datos aqui analizados se usarÃ¡ la siguiente linea de comando:

```
# Activa o ambiente QualityControl
conda activate QualityControl

# Crie uma pasta para salvar as reads limpas
mkdir 02.CleanData

# Crie uma pasta para salvar as reads nÃ£o pareadas
mkdir unpaired

# Corra Trimmomatic
trimmomatic PE -threads 10 00.RawData/sample1_1.fastq.gz 00.RawData/sample1_2.fastq.gz 02.CleanData/sample1_1_paired.fastq.gz unpaired/sample1_1_unpaired.fastq.gz 02.CleanData/sample1_2_paired.fastq.gz unpaired/sample1_2_unpaired.fastq.gz LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:150
```

ğŸ‡§ğŸ‡· Com o comando anterior vocÃª tem que rodar a linha de comando para cada amostra. Se quiser rodar todas as amostras de maneira automÃ¢tica Ã© possÃ­vel usar um *loop* `for` para executar esta tarefa.

> ğŸ‡ªğŸ‡¸ Con el comnado anterior ud tiene que correr esa lÃ­nea de comando para cada muestra. Si quiere correr todas las muestras de manera automÃ¡tica es posible usar un *loop* `for` para ejecutrar esta tarea. 

```
# loop
for i in 00.RawData/*1.fastq.gz 
do
BASE=$(basename $i 1.fastq.gz)
trimmomatic PE -threads 10 $i  00.RawData/${BASE}2.fastq.gz 02.CleanData/${BASE}1_paired.fq.gz unpaired/${BASE}1_unpaired.fq.gz 02.CleanData/${BASE}2_paired.fq.gz unpaired/${BASE}2_unpaired.fq.gz LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:100
done
```

**Sintaxe**
`trimmomatic PE -threads input_forward input_reverse output_forward_paired output_forward_unpaired output_reverse_paired output_reverse_unpaired [opÃ§Ãµes]`

ğŸ‡§ğŸ‡· O comando anterior tem muitas partes. Primeiro, o nome do comando Ã© `trimmomatic`, a continuaÃ§Ã£o a opÃ§Ã£o `PE` indica para o programa que as sequÃªncias que irÃ£o ser analisadas sÃ£o de tipo *paired end*. Depois se encontram os inputs, forward (pair1) e reverse (pair2). Depois estÃ£o os outputs, sendo o primeiro, as sequÃªncias forward pareadas (limpas) e nÃ£o pareadas ("descartadas") e depois igual para as sequÃªncias reverse. Por Ãºltimo se encontram os parÃ¢metros de filtragem. Para este caso usamos os parÃ¢metros `SLIDINGWINDOW`, `LEADING` e `TRAILING`. O primeiro de eles, gera uma janela deslizante, que em este caso vai de 4 em 4 bases, cÃ¡lcula a mÃ©dia do *Phred Score* e se estiver por baixo de 15 essas bases serÃ£o cortadas. `LEADING` corta bases do comeÃ§o da leitura que estejam por debaixo do *threshold* de qualidade, igualmente faz o `TRAILING` mas no final das leituras. `MINLEN` elimina todas as reads com tamanho menor ao informado. Trimmomatic tem muitos mais parÃ¢metros para customizar, veja no [manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).

Depois de rodar Trimmomatic Ã© necessÃ¡rio avaliar a qualidade das sequÃªncias limpas usando novamente FastQC.

> ğŸ‡ªğŸ‡¸ El comando anterior tiene muchas partes. Primero, el nombre del comando es `trimmomatic`, a continuaciÃ³n la opciÃ³n `PE` indica para el programa que las secuencias que irÃ¡n a ser analizadas son de tipo *paired end*. DespuÃ©s se encuentran los inputs, forward (pair1) y reverse (pair2). DespuÃ©s son los outputs, siendo primero las secuencias forward pareadas (limpias) y no pareadas ("descartadas") y despuÃ©s las secuencias reverse. Por Ãºltimo se encuentran los parametros de filtrado. Para este caso usamos los parametros `SLIDINGWINDOW`, `LEADING` y `TRAILING`. El primero de ellos, genera una ventana deslizante, que en este caso va de 4 en 4 bases, cÃ¡lcula el promedio del *Phred Score* y si estÃ¡ por debajo de 15 esas bases son cortadas. `LEADING` corta bases del comienzo de la lectura si estÃ¡n por debajo de *threshold* de calidad, lo mismo hace `TRAILING` pero al final de las lecturas. `MINLEN` elimina todas las lecturas con tamaÃ±o menor al informado. Trimmomatic tiene muchos mÃ¡s parÃ¡metros customizables, revise en el  [manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).
>
> DespuÃ©s de correr Trimmomatic es necesario evaluar la calidad de las secuencias generadas ("limpias") usando nuevamente FastQC.

```
fastqc -t 10 02.CleanData/* -o 01.FastqcReports/
```

Descargue los reportes `.html` de las secuencias pareadas (i.e. `01.FastqcReports/sample1_1_paired_fastqc.html` y `01.FastqcReports/sample1_2_paired_fastqc.html`).

FaÃ§a uma tabela com o nÃºmero de sequÃªncias antes e depois da trimagem para calcular a porcentagem de *reads* que sobreveviveram ao processo.

> ğŸ‡ªğŸ‡¸ Haga una tabla con el nÃºmero de secuencias antes y despuÃ©s de la depuraciÃ³n para calcular el porcentaje de *reads* que sobrevivieron al proceso.


### 1.3 Cobertura dos Metagenoma

ğŸ‡§ğŸ‡· AlÃ©m de limpar e trimar as sequÃªncias com baixa qualidade, Ã© necessÃ¡rio calcular a cobertura dos metagenomas.Este programa usa a redundÃ¢ncia de reads nos metagenomas para estimar a cobertura mÃ©dia e prediz a quantidade de sequÃªncias que sÃ£o requeridas para atingir o *"nearly complete coverage"*, definida como $â‰¥95$%  ou $â‰¥99$% de cobertura mÃ©dia. A ferramenta [**NonPareil v3.3.3**](https://nonpareil.readthedocs.io/en/latest/) serÃ¡ usada nesta etapa.

> ğŸ‡ªğŸ‡¸ AdemÃ¡s de limpiar y *trimar* las secuencias con baja calidad, es necesario calcular la cobertura de los metagenomas. Este programa usa la redundancia de las *reads* en los metagenomas para estimar la cobertura promedio y predice la cantidade de secuencias que son requeridas para conseguir el *"nearly complete coverage"*, definida como $â‰¥95$%  o $â‰¥99$% de la cobertura promedio. La herramienta [**NonPareil v3.3.3**](https://nonpareil.readthedocs.io/en/latest/) serÃ¡ usada en esta etapa.

### 1.3.1. InstalaÃ§Ã£o

ğŸ‡§ğŸ‡· [NonPareil v3.3.3](https://nonpareil.readthedocs.io/en/latest/) Ã© uma ferramenta que serÃ¡ usada para o cÃ¡lculo da cobertura dos metagenomas. Devido a incompatibilidades com a versÃ£o do Python usado para escrever esta ferramenta, ela serÃ¡ instalada em um ambiente diferente ao de controle de qualidade, chamado **NonPareil**.

> ğŸ‡ªğŸ‡¸ [NonPareil](https://nonpareil.readthedocs.io/en/latest/) es una herramienta que serÃ¡ usada para el cÃ¡lculo de la cobertura de los metagenomas. Debido a incompatibilidades con la versiÃ³n de Python usado para escribir esta herramienta, serÃ¡ instalada en un ambiente diferente al de control de calidad, llamado **NonPareil**.

```
# Crie o ambiente
conda create -n NonPareil

# Instale NonPareil
conda install -c bioconda nonpareil
```

### 1.3.2. Uso

Como *input* para esta anÃ¡lise sÃ³ Ã© necessÃ¡rio um pair de cada amostra, e deve estar sem compressÃ£o.


```
# Crie o diretÃ³rio pra o output
mkdir 03.NonPareil

# entre no directorio
cd 03.NonPareil

# Copie os pair 1 da pasta 02.CleanData

cp ../02.CleanData/*_1* ./

# Descomprimir 
gunzip -d *

```

ğŸ‡§ğŸ‡· Agora estÃ¡ tudo pronto para rodar a anÃ¡lise, mas antes disso tome-se o tempo para entender o comando que vai usar. Para conhecer que Ã© cada um dos argumentos, explore o menÃº de ajuda da ferramenta. 

> ğŸ‡ªğŸ‡¸ Ahora estÃ¡ todo listo para correr el anÃ¡lisis, pero antes de eso tÃ³mese el tiempo para entender el comando que va a usar. Para conocer que es cada uno de los argumentos, explore el menÃº de ayuda de la herramienta.

```
# Ative o ambiente NonPareil
conda activate NonPareil

# Explore o menÃº da ferramenta
nonpareil --help

# Comando do NonPareil para cada amostra
nohup nonpareil -s sample1.fq -T kmer -f fastq -b sample1 -t 6 &

```
No caso, se tiver vÃ¡rias amostras pode usar o seguinte loop para facilitar o processo.

```
for i in ./*.fq
do
BASE=$(basename $i .fq)
nonpareil -s $i -T kmer -f fastq -b $i -t 6
done
```

**Sintaxe**

* `-s`: caminho para o *input* 
* `-T`: algorÃ­tmo a ser usado. `kmer` Ã© recomendado para arquivos `.fastq` e `alignment` Ã© recomendado para arquivos `.fasta`.
* `-f`: indique aqui o formato do input (p.e. `fastq` ou `fasta`)
* `-b`: prefixo para os *outputs*
* `-t`: nÃºmero de threads

ğŸ‡§ğŸ‡· Ao terminar esse processo, o programa terÃ¡ criado varios [*outputs*](https://nonpareil.readthedocs.io/en/latest/redundancy.html#output) por cada amostra. Descarregue os arquivos `.npo`. Os quais sÃ£o tabelas delimitadas por tabulaÃ§Ãµes com seis colunas. A primeira coluna indica o esforÃ§o de sequenciamento (em nÃºmero de reads), as demais colunas tÃªm informaÃ§Ã£o sobre a distribuiÃ§Ã£o da redundÃ¢ncia a determinado esforÃ§o de sequenciamento. Usando os arquivos `.npo` e o R, pode grÃ¡ficar as curvas de saturaÃ§Ã£o. A continuaÃ§Ã£o se encontra o script.
AlÃ©m dos arquivos `.npo` Ã© necessÃ¡rio criar um arquivo chamado `samples.txt`, o qual deve ter trÃªs colunas (separadas por tabulaÃ§Ãµes), a primeira terÃ¡ o nome de cada arquivo `.npo`, a segunda o nome da amostra, e a terceira a cor em formato JSON que vai ser usada para a curva. Veja o exemplo abaixo

> ğŸ‡ªğŸ‡¸ Al terminar este proceso, el programa habrÃ¡ creado varios [*outputs*](https://nonpareil.readthedocs.io/en/latest/redundancy.html#output) por cada muestra. Descargue los archivos `.npo`. Los cuales son tablas delimitadas por tabulaciones con seis columnas. La primera columna indica el esfuerzo de secuenciaciÃ³n (en nÃºmero de *reads*), las demÃ¡s columnas tienen informaciÃ³n sobre la distribuciÃ³n de la redundancia a determinao esfuerzo de secuenciaciÃ³n. Usando los archivos `.npo` e R, puede grÃ¡ficar las curvas de saturaciÃ³n. A continuaciÃ³n se encuentra el script.
>
> AdemÃ¡s de los archivos `.npo` es necesario crear un archivo llamado `samples.txt`, el cual debe tener tres columnas (separadas por tabulaciones), la primera tendrÃ¡ el nombre de cada archivo `.npo`, la segunda el nombre de la muestra, y la tercera el color en formato JSON que va a ser usado para la curva. vea el ejemplo abajo

```
# Cria o arquivo samples.txt
nano samples.txt
```

Arquivo `samples.txt`

```
File    Name    Col
sample1.fq.npo    sample1   "#c151b6"
sample2.fq.npo    sample2   "#5eb04d"
sample3.fq.npo    sample3   "#7d65ce"
sample4.fq.npo    sample4   "#b5b246"
sample5.fq.npo    sample5   "#688ccd"
sample6.fq.npo    sample6   "#4bb092"
```

Esse arquivo pode ser criado em um bloco de notas ou em excel, mas deve ser separado por tabulaÃ§Ãµes.

```{r, eval=FALSE}
install.packages("Nonpareil") #para instalar o pacote, sÃ³ uma vez
library(Nonpareil) # ativa o pacote
setwd("~/03.NonPareil") # determina seu diretÃ³rio de trabalho (coloque o seu, onde colocou os arquivos .npo)

samples <- read.table('samples.txt', sep='\t', header=TRUE, as.is=TRUE); #lÃª o arquivo samples.txt com a informaÃ§Ã£o das amostras

attach(samples);
nps <- Nonpareil.set(File, col=Col, labels=Name, 
                     plot.opts=list(plot.observed=FALSE, 
                                    ylim = c(0, 1.05),
                                    legend.opts = FALSE)) #grafica as curvas

Nonpeil.legeng(nps, x.intersp=0.5, y.intersp=0.7, text.width=1.2) #coloca e personaliza a legenda
  
detach(samples);
summary(nps) #mostra o resumo em forma de tabela
```

Vai obter um grÃ¡fico com as curvas de saturaÃ§Ã£o de cada amostra, como este:

<img src="imgs/nonpareil.webp" align='center' width="80%">

ğŸ‡§ğŸ‡· As linhas tracejadas <font color='red'> vermelha </font> e <font color='gray'> cinza </font> representam os *threshold* de 95% e 99% da cobertura mÃ©dia, respeitivamente. O circulo em cada curva representa a cobertura atual das amostras, o ideal Ã© que esteja por cima do primeiro *threshold*. As curvas tambÃ©m apresentam a estimaÃ§Ã£o de quanto esforÃ§o de sequenciamento Ã© necessÃ¡rio (zetas no eixo x).

> ğŸ‡ªğŸ‡¸ Las lÃ­neas punteadas <font color='red'> roja </font> y <font color='gray'> gris </font> representam los *threshold* de 95% y 99% de cobertura promedio, respectivamente. El cÃ­rculo en cada curva representa la cobertura actual de las muestras, lo ideal es que estÃ©n por encima del primer *threshold*. Las curvas tambiÃ©n presentan la estimaciÃ³n de cuanto esfuerzo de secuenciaciÃ³n es necesario (flechas en el eje x). 


### 1.4. AnÃ¡lise de DistÃ¢ncias MinHash

ğŸ‡§ğŸ‡· ApÃ³s obter as sequÃªncias limpas, de boa qualidade, e determinar a cobertura dos metagenomas, Ã© possÃ­vel fazer a montagem. No entanto, pode ser incluÃ­do um passo extra antes da montagem e Ã© verificar a similaridade dos datasets para determinar se pode ser usada a abordagem de *co-assembly*, onde sÃ£o misturadas as *reads* de vÃ¡rios metagenomas para gerar os contigs. O programa [**Mash v2.3**](https://mash.readthedocs.io/en/latest/) usa uma tÃ©cnica chamada reduÃ§Ã£o de dimensionalidad *MinHash* que avalia as distÃ¢ncias um a um entre os datasets. 

> ğŸ‡ªğŸ‡¸ DespuÃ©s de obtener las secuencias limpias, de buena calidad, y determinar la cobertura de los metagenomas, es posible hacer el montaje. Sin embargo, puede ser incluÃ­do un paso extra antes del montaje y es verificar la similaridade de los datasets para determinar si puede ser usado el abordaje de *co-assembly*, donde son mezcladas las *reads* de varios metagenomas para generar los contigs. El programa [**Mash v2.3**](https://mash.readthedocs.io/en/latest/) usa una tÃ©cnica llamada reducciÃ³n de dimensionalidad *MinHash* que evalua las distancias un a un entre los datasets.

### 1.4.1. InstalaÃ§Ã£o

ğŸ‡§ğŸ‡· [Mash v2.3](https://mash.readthedocs.io/en/latest/) Ã© uma ferramenta que usa a tÃ©cnica de reduÃ§Ã£o da dimensionalidade *MinHash* para calcular as distÃ¢ncias um a um entre os datasets, assim, Ã© possÃ­vel determinar se os metagenomas sÃ£o similares ou nÃ£o para serem montados usando *co-assembly*. 

ğŸ‡§ğŸ‡· Por ser considerada uma ferramenta que participa no processo de assembly, serÃ¡ instalada dentro de um ambiente virtual chamado **Assembly**.

> ğŸ‡ªğŸ‡¸ [Mash](https://mash.readthedocs.io/en/latest/) es una herramienta que usa la tÃ©cnica de reducciÃ³n de dimensionalidad *MinHash* para calcular las distancias un a un entre los datasets, asÃ­, es posible determinar si los metagenomas son similares o no para ser ensamblados usando *co-assembly*.
>
> ğŸ‡ªğŸ‡¸ Por ser considera una herramienta que participa en el proceso de ensamble, serÃ¡ instalada dentro de un ambiente virtual llamado **Assebly**.

```
# Crie o ambiente virtual
conda create -n Assembly

# Instale Mash
conda install -c bioconda mash
```

### 1.4.2. Uso

```
## Crie uma pasta para o output
mkdir 04.MinHash
```

ğŸ‡§ğŸ‡·  O primeiro paso Ã© concatenar os reads 1 e 2, e armazenar eles na nova pasta criada `04.MinHash/`.

**Nota:** Se vocÃª trimou suas sequÃªncias, deve usar os arquivos gerados pelo **Trimmomatic** na pasta `02.CleanData`, se pelo contrÃ¡rio suas sequÃªncias estavam de boa qualidade e nÃ£o foi necessÃ¡rio trimar, use os arquivos originais, que estÃ£o dentro da pasta `00.RawData/`.

> ğŸ‡ªğŸ‡¸ 
>
>**Nota:** Si usted filtrÃ³ sus secuencias, debe usar los archivos generados por **Trimmomatic** en el directorio `02.CleanData`, si por el contrario sus secuencias estaban de buena calidade y no fue necesario filtrar, use los archivos originales, que estÃ¡n dentro de la carpeta `00.RawData`.

```
for i in 02.CleanData/*_1_paired.fq.gz
do
BASE=$(basename $i _1_paired.fq.gz)
cat $i 02.CleanData/${BASE}_2_paired.fastq.gz > 04.MinHash/${BASE}.fq
done
```

ğŸ‡§ğŸ‡· Depois serÃ¡ criado um *sketch* para combinar todas as amostras. Usando `mash info` pode verificar o conteÃºdo e, em seguida, estimar as distÃ¢ncias par a par:

> ğŸ‡ªğŸ‡¸ 
>
> DespuÃ©s serÃ¡ creado un *sketch* para combinar todas las muestras. Usando `mash info` puede verificar el contenido y, en seguida, estimar las distancias par a par:

```
mash sketch -o 04.MinHash/reference 04.MinHash/sample1.fq 04.MinHash/sample2.fq 04.MinHash/sample3.fq 04.MinHash/sample4.fq 04.MinHash/sample5.fq 04.MinHash/sample6.fq

#verifiyng
mash info 04.MinHash/reference.msh
```

**Sintaxe**

`mash sketch -o reference [inputs]`

`mash info reference.msh`

* `sketch`: Comando para criar um *sketch*, combinando todas as amostras, recomendado quando tÃªm mais de trÃªs amostras.
* `-o`: caminho pro *output*, criarÃ¡ um *sketch* `.msh`.
* `inputs`: liste os inputs (sequencias concatenadas dos pair1 e pair2)
* `info`: pode verificar o conteÃºdo do `sketch`
* `reference.msh`: *sketch* criado

Por Ãºltimo, calcule as distÃ¢ncias entre cada par de metagenomas usando `mash dist` e salve o resultado no arquivo `distancesOutput.tsv`.

```
mash dist 04.MinHash/reference.msh 04.MinHash/reference.msh -p 6 > 04.MinHash/distancesOutputFinal.tsv
```

**Sintaxe**
`mash dist [reference] [query] [options]`

* `dist`: comando para calcular as distÃ¢ncias entre cada par de mategenomas, baseado na distÃ¢ncia *MinHash*.
* `reference`: aqui pode colocar o *sketch* criado, ou arquivos `.fq`, `fasta`.
* `query`: Ã­dem
* `-p`: nÃºmero de threads

Descarregue o output (`04.MinHash/distancesOutputFinal.tsv`) e use o seguinte script do R para plotar um heatmap com as distÃ¢ncias.

```{r, eval=FALSE}
setwd("~/04.MinHash/")

 data <- read.table("distancesOutputFinal.tsv")

 #install.packages("vegan")
 library(vegan)
 set.seed(2)
 
 dst = as.matrix(data)
 
 #install.packages("gplots")
 library(gplots)
 set.seed(2)
 x <- matrix(rnorm(100), nrow = 5)
 dist.fn <- function(x) as.dist(1-cor(t(x)))
 hclust.com <- function(x) hclust(x, method="complete")
 
 dev.off()
 h.ori <- heatmap.2(dst, trace="none", distfun=dist.fn, 
                    hclustfun=hclust.com,dendrogram = "row",main = "MinHash Clusterization",
                    cexRow=0.8, # Tamanho do texto no eixo y
                    cexCol=0.8,adjCol = c(0.5,0.2),
                    adjRow = c(0.05,0.),
                    srtCol=90,offsetRow=0, offsetCol=0, keysize = 1.5)
```

Vai obter um heatmap com clusterizaÃ§Ã£o similar a este:

<img src="imgs/distances.png" align='center' width="80%">

FaÃ§a *co-assembly* para *datasets* com distÃ¢ncias menores de 0.1, entre ellas.


## 2. Montagem dos Metagenomas

ğŸ‡§ğŸ‡· A montagem dos metagenomas Ã© a etapa mais importante do processo, porque os demais passos para adelante dependen de uma boa montagem. No caso dos metagenomas, se trata de um proceso que nÃ£o Ã© para nada trivial, requer um grande esforÃ§o computacional. Por este motivo, serÃ£o testados vÃ¡rios parÃ¢metros, para comparar cada montagem e decidir qual Ã© o melhor para Ã¡s anÃ¡lises *downstream*. Neste processo serÃ¡ usado o montador [Spades v3.15.3](https://github.com/ablab/spades).

> ğŸ‡ªğŸ‡¸ El montaje de los metagenomas es la etapa mÃ¡s importante del proceso, porque los demÃ¡s pasos para adelante dependen de un buen ensamble. En el caso de los metagenomas, se trata de un proceso que no es para nada trivial, requiere un gran esfuerzo computacional. Por este motivo serÃ¡n testados varios parÃ¡metros, para comparar cada ensamble y decidir cual es el mejor para los anÃ¡lisis *downstream*. En este proceso serÃ¡ usado el montado [Spades v3.15.3](https://github.com/ablab/spades).

### 2.1. InstalaÃ§Ã£o

ğŸ‡§ğŸ‡· [Spades v3.15.3](https://github.com/ablab/spades) Ã© um dos montadores de genomas e metagenomas, mais conhecido e com melhores resultados, pode ser usado tanto para leituras curtas como longas. Leia atentamente o [manual](http://cab.spbu.ru/files/release3.15.2/manual.html), jÃ¡ que este programa tem muitas opÃ§Ãµes diferentes. Spades usa o algorÃ­tmo do *Grafo de Bruijn* para a montagem das secuÃªncias.

Siga as seguintes instruÃ§Ãµes para a instalaÃ§Ã£o do **Spades** dentro do ambiente virtual *Assembly*.

> ğŸ‡ªğŸ‡¸ [Spades v3.15.3](https://github.com/ablab/spades) es uno de los ensambladores de genomas y metagenomas, mÃ¡s conocido y con mejores resultados, puede ser usado tanto para lecturas cortas como largas. Lea atentamente el [manual](http://cab.spbu.ru/files/release3.15.2/manual.html), ya que este programa tiene muchas opciones diferentes. Spades usa el algorÃ­tmo del *Grafo de Bruijn* para el montaje de las secuencias. 
>
> Siga las siguientes instrucciones para la instalaciÃ³n de **Spades** dentro del ambiente virtual *Assembly*.

```
# Active el ambiente virtual
conda activate Assembly

# Instale Spades
conda install -c bioconda spades
```

### 2.2. Uso

ğŸ‡§ğŸ‡· Agora Ã© momento de fazer as montagens. Use o resultado da anÃ¡lisis de distÃ¢ncias *MinHash* para decidir como serÃ£o feitos as montagens. Amostras muito prÃ³ximas pode fazer *co-assembly*, para amostras distantes Ã© recomendado montar individualmente. Opcionalmente podem ser usadas as sequÃªncias no pareadas (sequÃªncias "descartadas" pelo Trimmomatic). O montador usado neste mÃ©todo serÃ¡ [Spades](https://github.com/ablab/spades). 

A continuaÃ§Ã£o se encontram os comandos se sua montagem for individual:

> ğŸ‡ªğŸ‡¸ Ahora es el momento de hacer los ensamblajes. Use el resultado del anÃ¡lisis de distancias *MinHash* para decidir como serÃ¡n hechos los montajes. Muestras muy prÃ³xima puede hacer *co-assembly*, para muestras distantes es recomendado montar individualmente. Opcionalmente pueden ser las secuencias no pareadas (secuencias "descartadas" por Trimmomatic). El montador usado en este mÃ©todo serÃ¡ [Spades](https://github.com/ablab/spades). 

1. Criar um diretÃ³rio para todas as montagens

```
mkdir 05.Assembly
```

2. Se vocÃª quiser usar as *reads* no pareadas (saÃ­da do **Trimmomatic**), deve primeiro concatenarlas em um arquivo sÃ³

```
cat unpaired/sample1_1_unpaired.fq.gz unpaired/sample1_2_unpaired.fq.gz > unpaired/sample1_12_unpaired.fq.gz
```

3. Montagem com MetaSpades

```
metaspades.py -o 05.Assembly/sample1/ -1 02.CleanData/sample1_1_paired.fq.gz -2 02.CleanData/sample1_2_paired.fq.gz -s unpaired/sample1_12_unpaired.fq.gz -t 6 -m 100 -k 21,29,39,59,79,99,119
```

**Sintaxe**

* `metaspades.py`: script para montar metagenomas
* `-o`: caminho para diretÃ³rio de saÃ­da
* `-1`: caminho para diretÃ³rio do pair1
* `-2`: caminho para diretÃ³rio do pair2
* `-s`: caminho para diretÃ³rio das *reads* no pareadas
* `-t`: nÃºmero de threads
* `-m`: MemÃ³ria em gigas (mÃ¡ximo)
* `-k`: lista de *k-mers*

ğŸ‡§ğŸ‡· Se sua montagem for no modo *co-assembly* deve fazer uma etapa anterior, onde vai concatenar todos os pair1 das amostras que serÃ£o montadas e todos os pair2 das mesmas. 

> ğŸ‡ªğŸ‡¸  Si su ensamblaje es en el modo *co-assembly* debe hacer una etapa anterior, donde va a concatenar todos los pair1 de las muestras que serÃ¡n montadas y todos los pair2 de las mismas. 

1. Concatene os pair 1

```
cat 02.CleanData/sample4_1.fq.gz 02.CleanData/sample5_1.fq.gz > 02.CleanData/sample45_1.fq.gz
```

2. Concatene os pair 2

```
cat 02.CleanData/sample4_2.fq.gz 02.CleanData/sample5_2.fq.gz > 02.CleanData/sample45_2.fq.gz
```

3. Se vocÃª quiser usar as *reads* no pareadas (saÃ­da do **Trimmomatic**), deve primeiro concatenarlas em um arquivo sÃ³

```
cat unpaired/sample4_1_unpaired.fq.gz unpaired/sample4_2_unpaired.fq.gz unpaired/sample5_1_unpaired.fq.gz unpaired/sample5_2_unpaired.fq.gz > unpaired/sample45_12_unpaired.fq.gz
```

4. Montagem com MetaSpades

```
metaspades.py -o 05.Assembly/sample45/ -1 02.CleanData/sample45_1_paired.fq.gz -2 02.CleanData/sample45_2_paired.fq.gz -s unpaired/sample45_12_unpaired.fq.gz -t 6 -m 100 -k 21,29,39,59,79,99,119
```


