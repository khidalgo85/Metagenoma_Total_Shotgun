
<!-- README.md is generated from README.Rmd. Please edit that file -->
<!-- badges: start -->

![forthebadge](https://img.shields.io/badge/GEMM-Building-orange)
![forthebadge](https://forthebadge.com/images/badges/built-with-science.svg)

<!-- badges: end -->

# An√°lise do Metagenoma total - Shotgun <img src="imgs/1.png" align="right" width = "120px"/>

**Autor: MsC. Kelly Hidalgo**

üáßüá∑ Pipeline para a montagem e anota√ß√£o funcional de metagenomas totais.
Este pipeline contempla todas as etapas do processamento, desde a
avalia√ß√£o da qualidade das sequ√™ncias, trimagem, montagem, c√°lculo da
cobertura, predi√ß√£o e anota√ß√£o funcional e taxon√¥mica dos genes.

> üá™üá∏Pipeline para montaje y anotaci√≥n funcional de metagenomas totales.
> Este pipeline contempla todas las etapas del procesamiento, desde la
> evaluaci√≥n de la calidad de las secuencias, *trimming*, montaje,
> c√°lculo de la cobertura, predicci√≥n y anotaci√≥n funcional y taxon√≥mica
> de genes.

## Ferramientas bioinform√°ticas

## 0. Instala√ß√£o

### 0.1. Anaconda

üáßüá∑ √â recomend√°vel instalar Anaconda, pois √© a forma mais f√°cil para
instalar as ferramentas bioinform√°ticas necess√°rias pro desenvolvimento
deste pipeline. Anaconda √© uma distribui√ß√£o livre e aberta das
linguagens *Python* e *R*, utilizada na ci√™ncia de dados e
bioinform√°tica. As diferente vers√µes dos programas se administram
mediante um sinstema de gest√£o chamado *conda*, o qual faz bastante
simples instalar, rodar e atualizar programas.
[Aqui](https://conda.io/projects/conda/en/latest/user-guide/install/index.html)
se encontram as instru√ß√µes para a instala√ß√£o de Anaconda.

Depois de instalado, *Anaconda* e o gestor *Conda*, podram ser criados
*ambientes virtuais* par a instala√ß√£o das diferentes ferramentas
bioinform√°tica que ser√£o usadas.

> üá™üá∏ Es recomendable instalar Anaconda, pues es la forma m√°s f√°cil para
> instalar las herramientas bioinform√°ticas necesarias para el
> desarrollo de este pipeline. Anaconda es una distribuci√≥n libre y
> abierta de los lenguajes *Python* y *R*, utilizada en ciencia de datos
> y bioinform√°tica. Las diferentes versiones de los programas se
> administran mediante un sistema de gesti√≥n llamado *conda*, el cual
> hace bastante sencillo instalar, correr y actualizar programas.
> [Aqui](https://conda.io/projects/conda/en/latest/user-guide/install/index.html)
> se encuentran las instrucciones para la instalaci√≥n de Anaconda.
>
> Despu√©s de instalado *Anaconda* y su gestor *Conda*, podran ser
> creados *ambientes virtuales* para la instalaci√≥n de las diferentes
> herramientas bioinform√°ticas que ser√°n usadas.

### 0.2. FastQC

üáßüá∑ [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/) √©
uma ferramenta para avaliar graficamente a qualidade das sequencias de
Illumina.

Las instru√ß√µes para a instala√ß√£o usando conda se encontram
[aqui](https://anaconda.org/bioconda/fastqc). No entanto neste tutorial
tamb√©m ser√£o apresentados.

Como j√° foi explicado anteriormente, com conda √© poss√≠vel criar
ambientes virtuais para instalar as ferramentas bioinform√°ticas. O
primeiro ambiente que ser√° criado se chamar√° **QualityControl**, onde se
instalaram os programas relacionados com esse processo.

> üá™üá∏ [FastQC](http://www.bioinformatics.babraham.ac.uk/projects/fastqc/)
> es una herramienta para evaluar graficamente la calidad de las
> secuencias de Illumina.
>
> Las instrucciones para instalaci√≥n usando conda se encuentran
> [aqui](https://anaconda.org/bioconda/fastqc). Sin embargo aqui en este
> tutorial tambi√©n ser√°n presentadas
>
> Como ya fue explicado anteriorimente, con conda es posible crear
> ambientes virutuales para instalar las herramientas bioinform√°ticas.
> El primer ambiente que ser√° creado se llamar√° **QualityControl**,
> donde se instalaran los programas relacionados con este proceso.

    conda create -n QualityControl

üáßüá∑ Durante o processo, o sistema perguntar√° se deseja proceder com a
crea√ß√£o do ambiente, com as op√ß√µes y/n (sim ou n√£o). Escreva `y` e
depois disso o ambiente virutal estar√° criado.

Para instalar as ferramentas dentro do ambiente anteriormente criado, √©
necess√°rio ativ√°-lo.

> üá™üá∏ Durante el proceso, el sistema preguntar√° s√≠ desea proceder con la
> creaci√≥n del ambiente, con las opciones y/n (si o no). Escriba `y` y
> despu√©s de eso el ambiente virtual estar√° creado.
>
> Para instalar las herramientas dentro del ambiente anteriormente
> creado, es necesario activarlo

    conda activate QualityControl

üáßüá∑ O ambiente estar√° ativo quando o nome se encontre ao come√ßo da linha
do comando, asssim: `(QualityControl) user@server:~/$`. Posteriormente
se procede √† instala√ß√£o do programa:

> üá™üá∏ El ambiente estar√° activo cuando el nombre de √©ste se encuentra en
> el comienzo de la linea de comando, as√≠:
> `(QualityControl) user@server:~/$`.
>
> Posteriormente se procede a la instalaci√≥n del programa:

    conda install -c bioconda fastqc

### 0.3. Trimmomatic v0.39

üáßüá∑ [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) √© um
programa pra filtrar (remover) leituras ou *reads* curtas de baixa
qualidade.

Como se trata de uma ferramenta que participa dentro do processo de
control de qualidade, ser√° instalada dentro do ambiente virtual
**QualityControl**.

> üá™üá∏ [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) es un
> programa para filtrar (remover) lecturas o *reads* cortas de baja
> calidad.
>
> Como se trata de una herramienta que participa dentro del proceso de
> control de calidad, ser√° instalada dentro del ambiente virtual
> **QualityControl**

    # Si no est√° activado el ambiente
    conda activate QualityControl

    # Instale Trimmomatic
    conda install -c bioconda trimmomatic

### 0.4. NonPareil v3.3.3

üáßüá∑ [NonPareil](https://nonpareil.readthedocs.io/en/latest/) √© uma
ferramenta que ser√° usada para o c√°lculo da cobertura dos metagenomas.
Devido a incompatibilidades com a vers√£o do Python usado para escrever
esta ferramenta, ela ser√° instalada em um ambiente diferente ao de
controle de qualidade, chamado **NonPareil**.

> üá™üá∏ [NonPareil](https://nonpareil.readthedocs.io/en/latest/) es una
> herramienta que ser√° usada para el c√°lculo de la cobertura de los
> metagenomas. Debido a incompatibilidades con la versi√≥n de Python
> usado para escribir esta herramienta, ser√° instalada en un ambiente
> diferente al de control de calidad, llamado **NonPareil**.

    # Crie o ambiente
    conda create -n NonPareil

    # Instale NonPareil
    conda install -c bioconda nonpareil

### 0.5. Mash v2.3

üáßüá∑ [Mash](https://mash.readthedocs.io/en/latest/) √© uma ferramenta que
usa a t√©cnica de redu√ß√£o da dimensionalidade *MinHash* para calcular as
dist√¢ncias um a um entre os datasets, assim, √© poss√≠vel determinar se os
metagenomas s√£o similares ou n√£o para serem montados usando
*co-assembly*. Por ser considerada uma ferramenta que participa no
processo de assembly, ser√° instalada dentro de um ambiente virtual
chamado **Assembly**.

> üá™üá∏ [Mash](https://mash.readthedocs.io/en/latest/) es una herramienta
> que usa la t√©cnica de reducci√≥n de dimensionalidad *MinHash* para
> calcular las distancias un a un entre los datasets, as√≠, es posible
> determinar si los metagenomas son similares o no para ser ensamblados
> usando *co-assembly*.
>
> Por ser considera una herramienta que participa en el proceso de
> ensamble, ser√° instalada dentro de un ambiente virtual llamado
> **Assebly**.

    # Crie o ambiente virtual
    conda create -n Assembly

    # Instale Mash
    conda install -c bioconda mash

------------------------------------------------------------------------

## 1. Organizando os dados

### 1.1. Sequ√™ncias

üáßüá∑ En este tutorial ser√£o usados 4 meteganomas, pode decarreg√°-los
[aqui](colgarlosdatos.com).

Antes de descarregar os *datasets*, crie os seguintes direct√≥rios para a
organiza√ß√£o dos dados.

> üá™üá∏ En este tutorial ser√°n usados 4 metagenomas, puede descargarlos
> [aqui](colgarlosdatos.com).
>
> Antes de descargar los *datasets*, cree los siguientes directorios
> para la organizaci√≥n de los datos.

    # Crie uma pasta ra√≠z chamada metagenomica
    mkdir metagenomica
    cd metagenomica/

    # Crie um diret√≥rio para colocar os dados
    mkdir 00.RawData
    cd 00.RawData/

üáßüá∑ Use o comando `wget` para descarregar os dados desde este
[link](colgarlosdatos.com).

> üá™üá∏ Use el comando `wget` para descargarlos los datos desde este
> [link](colgarlosdatos.com).

## 2. Controle de Qualidade

### 2.1. FastQC

üáßüá∑ A primeira etapa do processo √© a avalia√ß√£o da qualidade das
sequ√™ncias cortas (Illumina paired end) usando *FastQC*, com o objetivo
de determianr se √© necess√°rio trimar ou filtrar as sequ√™ncias da baixa
qualidade para nos pr√≥ximos pasos.

Esta etapa √© para identificar principalmente as sequ√™ncias *outlier* com
baixa qualidade (*Q*‚ÄÑ&lt;‚ÄÑ20)

Ative o ambiente `QualityControl`:

> üá™üá∏ La primera etapa del proceso es la evaluaci√≥n de la calidad de las
> secuencias cortas (Illumina paired end) usando *FastQC*, con el
> objetivo de determinar s√≠ es necesario trimar o filtrar las secuencias
> de baja calidad en los pr√≥ximos pasos.
>
> √âsta etapa es para identificar principalmente las secuencias *outlier*
> con baja calidad (*Q*‚ÄÑ&lt;‚ÄÑ20).
>
> Active el ambiente `QualityControl`:

    conda activate QualityControl

    ## Onde vc est√°?
    pwd

üáßüá∑ Deve etsar em `~/metagenomica/`.. Se esse n√£o √© o resultado del
comando `pwd`, use o comando `cd` para chegar no diret√≥rio desejado.

> üá™üá∏ Debe estar em `~/metagenomica/`. Si ese no es el resultado del
> comando `pwd`, use el comando `cd` para llegar en el directorio base.

Execute **FastQC**:

    ## Crie um direct√≥rio para salvar o output do FastQC
    mkdir 01.FastqcReports
    ## Run usando 10 threads
    fastqc -t 10 00.RawData/* -o 01.FastqcReports/

**Sintaxis** fastqc \[op√ß√µes\] input -o output

üáßüá∑ O comando `fastqc` tem v√°rias op√ß√µes ou par√¢metros, entre eles,
escolher o n√∫mero de n√∫cleos da m√°quina para rodar a an√°lise, para este
exemplo `-t 10`. O input √© o diret√≥rio que contem as sequ√™ncias
`00.RawData/*`, o `*` indica ao sistema que pode analisar todos os
arquivos que est√£o dentro desse diret√≥rio. O output, indicado pelo
par√¢mtero `-o`, √© o diret√≥rio onde se deseja que sejam guardados os
resultados da an√°lise. A continua√ß√£o se encontram uma explica√ß√£o
detalhada de cada output gerado.

> üá™üá∏ El comando `fastqc` tiene varias opciones o parametros, entre
> ellas, escoger el n√∫mero de n√∫cleos de la m√°quina para correr el
> an√°lisis, para este caso `-t 10`. El input es el directorio que
> contiene las secuencias `00.RawData/*`, el `*` indica al sistema que
> puede analizar todos los archivos que est√°n dentro de ese directorio.
> El output, indicado por el parametro `-o`, es el directorio donde se
> desea que sean guardados los resultados del an√°lisis. A continuaci√≥n
> se encuentra una explicaci√≥n detallada de cada output generado.

**Outputs**

üáßüá∑

-   Reportes html `.html`: Aqui √© poss√≠vel ver toda informa√ß√£o de
    qualidade graficamente.

-   Zip files `.zip`: Aqui se encontram cada um dos gr√°ficos de maneira
    separada. **IGNORE**

Descaregue os arquivos `html` e explore no seu *web browser*.

Observe as estat√≠sticas b√°sicas que se encontram na primeira tabela.
Al√≠, voc√™ pode saber quantas sequ√™ncias tem, o tamanho e o %GC. O
gr√°fico mais importante para saber a quealidade das leituras, √© o
primeiro, *Per base sequence quality*. Este gr√°fico √© um boxplot com a
distribui√ß√£o dos valores de qualidade *Phred Score* (eje y) em cada um
dos nucleot√≠deos das leituras (eje x). Se consideram sequ√™ncias de
excelente qualidade quando o *P**h**r**e**d**S**c**o**r**e*‚ÄÑ&gt;‚ÄÑ30. √â
norla que o pair 2 apresente uma qualidade um pouco inferior ao pair 1.

> üá™üá∏ Observe las estad√≠sticas b√°sicas que se encuentran en la primera
> tabla. All√≠, ud puede saber cuantas secuencias tiene, el tama√±o y el
> %GC. El gr√°fico m√°s importante para saber la calidad de las lecturas
> es el primero, *Per base sequence quality*. Este gr√°fico es un boxblot
> con la distribuci√≥n de los valores de calidad *Phred Score* (eje y) en
> cada uno de los nucle√≥tidos de las lecturas (eje x). Se consideran
> secuencias de excelente calidad cuando el
> *P**h**r**e**d**S**c**o**r**e*‚ÄÑ&gt;‚ÄÑ30. Es normal que el pair 2
> presente una calidad un poco inferior al pair 1.

### 2.2. Trimmomatic

üáßüá∑ Segundo foi avaliado no controle de qualidade, pode ser necess√°rio
filtrar algumas leituras com qualidade baixa.

O programa Trimmomatic tem v√°rios par√¢metros que podem ser considerados
para filtrar reads com baixa qualidade. Aqui usaremos alguns. Se quer
saber que outros par√¢metros e como funciona cada um deles, consulte o
[manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).

Para os dados aqui analizados se usara a seguinte linha de comando:

> üá™üá∏ Seg√∫n fue evaluado en el control de calidad, puede ser necesario
> filtrar algunas lecturas con calidad baja.
>
> El programa Trimmomatic tiene v√°rios parametros que pueden ser
> considerados para filtrar lecturas con baja calidad. Aqui usaremos
> algunos. Si quiere saber que otros parametros y como funciona cada uno
> de ellos, consulte el
> [manual](http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf).
>
> Para los datos aqui analizados se usar√° la siguiente linea de comando:

    # Activa o ambiente QualityControl
    conda activate QualityControl

    # Crie uma pasta para salvar as reads limpas
    mkdir 02.CleandData

    # Crie uma pasta para salvar as reads n√£o pareadas
    mkdir unpaired

    # Corra Trimmomatic
    trimmomatic PE -threads 10 00.RawData/sample1_1.fastq.gz 00.RawData/sample1_2.fastq.gz 02.CleandData/sample1_1_paired.fastq.gz unpaired/sample1_1_unpaired.fastq.gz 02.CleandData/sample1_2_paired.fastq.gz unpaired/sample1_2_unpaired.fastq.gz LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:150

üáßüá∑ Com o comando anterior voc√™ tem que rodar a linha de comando para
cada amostra. Se quiser rodar todas as amostras de maneira autom√¢tica √©
poss√≠vel usar um *loop* `for` para executar esta tarefa.

> üá™üá∏ Con el comnado anterior ud tiene que correr esa l√≠nea de comando
> para cada muestra. Si quiere correr todas las muestras de manera
> autom√°tica es posible usar un *loop* `for` para ejecutrar esta tarea.

    # loop
    for i in 00.RawData/*1.fq.gz 
    do
    BASE=$(basename $i 1.fq.gz)
    trimmomatic PE -threads 20 $i  00.RawData/${BASE}2.fq.gz 02.CleanData/${BASE}1_paired.fq.gz unpaired/${BASE}1_unpaired.fq.gz 02.CleanData/${BASE}2_paired.fq.gz unpaired/${BASE}2_unpaired.fq.gz LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:150
    done

**Sintaxis** trimmomatic PE -threads input\_forward input\_reverse
output\_forward\_paired output\_forward\_unpaired
output\_reverse\_paired output\_reverse\_unpaired \[op√ß√µes\]

üáßüá∑ O comando anterior tem muitas partes. Primeiro, o nome do comando √©
`trimmomatic`, a continua√ß√£o a op√ß√£o `PE` indica para o programa que as
sequ√™ncias que ir√£o ser analisadas s√£o de tipo *paired end*. Depois se
encontram os inputs, forward (pair1) e reverse (pair2). Depois est√£o os
outputs, sendo o primeiro, as sequ√™ncias forward pareadas (limpas) e n√£o
pareadas (‚Äúdescartadas‚Äù) e depois igual para as sequ√™ncias reverse. Por
√∫ltimo se encontram os par√¢metros de filtragem. Para este caso usamos os
par√¢metros `SLIDINGWINDOW`, `LEADING` e `TRAILING`. O primeiro de eles,
gera uma janela deslizante, que em este caso vai de 4 em 4 bases,
c√°lcula a m√©dia do *Phred Score* e se estiver por baixo de 15 essas
bases ser√£o cortadas. `LEADING` corta bases do come√ßo da leitura que
estejam por debaixo do *threshold* de qualidade, igualmente faz o
`TRAILING` mas no final das leituras. `MINLEN` elimina todas as reads
com tamanho menor ao informado.

Depois de rodar Trimmomatic √© necess√°rio avaliar a qualidade das
sequ√™ncias limpas usando novamente FastQC.

> üá™üá∏ El comando anterior tiene muchas partes. Primero, el nombre del
> comando es `trimmomatic`, a continuaci√≥n la opci√≥n `PE` indica para el
> programa que las secuencias que ir√°n a ser analizadas son de tipo
> *paired end*. Despu√©s se encuentran los inputs, forward (pair1) y
> reverse (pair2). Despu√©s son los outputs, siendo primero las
> secuencias forward pareadas (limpias) y no pareadas (‚Äúdescartadas‚Äù) y
> despu√©s las secuencias reverse. Por √∫ltimo se encuentran los
> parametros de filtrado. Para este caso usamos los parametros
> `SLIDINGWINDOW`, `LEADING` y `TRAILING`. El primero de ellos, genera
> una ventana deslizante, que en este caso va de 4 en 4 bases, c√°lcula
> el promedio del *Phred Score* y si est√° por debajo de 15 esas bases
> son cortadas. `LEADING` corta bases del comienzo de la lectura si
> est√°n por debajo de *threshold* de calidad, lo mismo hace `TRAILING`
> pero al final de las lecturas. `MINLEN` elimina todas las lecturas con
> tama√±o menor al informado.
>
> Despu√©s de correr Trimmomatic es necesario evaluar la calidad de las
> secuencias generadas (‚Äúlimpias‚Äù) usando nuevamente FastQC.

    fastqc -t 10 02.CleandData/* -o 01.FastqcReports/

Descargue los reportes `.html` de las secuencias pareadas
(i.e.¬†`01.FastqcReports/sample1_1_paired_fastqc.html` y
`01.FastqcReports/sample1_2_paired_fastqc.html`).

### 2.3 Cobertura dos Metagenomas

üáßüá∑ Al√©m de limpar e trimar as sequ√™ncias com baixa qualidade, √©
necess√°rio calcular a cobertura dos metagenomas.Este programa usa a
redund√¢ncia de reads nos metagenomas para estimar a cobertura m√©dia e
prediz a quantidade de sequ√™ncias que s√£o requeridas para atingir o
*‚Äúnearly complete coverage‚Äù*, definida como ‚ÄÑ‚â•‚ÄÑ95% ou ‚ÄÑ‚â•‚ÄÑ99% de
cobertura m√©dia. A ferramenta **NonPareil** ser√° usada nesta etapa.

Como *input* para esta an√°lise s√≥ √© necess√°rio um pair de cada amostra,
e deve estar sem compress√£o.

> üá™üá∏ Adem√°s de limpiar y *trimar* las secuencias con baja calidad, es
> necesario calcular la cobertura de los metagenomas. Este programa usa
> la redundancia de las *reads* en los metagenomas para estimar la
> cobertura promedio y predice la cantidade de secuencias que son
> requeridas para conseguir el *‚Äúnearly complete coverage‚Äù*, definida
> como ‚ÄÑ‚â•‚ÄÑ95% o ‚ÄÑ‚â•‚ÄÑ99% de la cobertura promedio. La herramienta
> **NonPareil** ser√° usada en esta etapa.
>
> Como *input* para este an√°lisis solo es necesario un par de cada
> muestra, y debe estar sin compresi√≥n.

    # Crie o diret√≥rio pra o output
    mkdir 02.NonPareil

    # Copie todos os pair 1 ao novo diret√≥rio

    cp 00.RawData/*_1.fq.gz 02.NonPareil

    # Entre no diret√≥rio

    cd 02.NonPareil 

    # Descomprima os arquivos 
    gunzip *.gz 

    # Loop para convertir todos os arquivos de fastq to fasta
    for i in ./*
    do
    SAMPLE=$(basename $i _1.fq)
    cat $i | paste - - - - | awk 'BEGIN{FS="\t"}{print ">"substr($1,2)"\n"$2}' > ${SAMPLE}_1.fasta
    done

üáßüá∑ Agora est√° tudo pronto para rodar a an√°lise, mas antes disso tome-se
o tempo para entender o comando que vai usar. Para conhecer que √© cada
um dos argumentos, explore o men√∫ de ajuda da ferramenta.

> üá™üá∏ Ahora est√° todo listo para correr el an√°lisis, pero antes de eso
> t√≥mese el tiempo para entender el comando que va a usar. Para conocer
> que es cada uno de los argumentos, explore el men√∫ de ayuda de la
> herramienta.

    # Explore o men√∫ da ferramenta
    nonpareil --help

    # Comando do NonPareil para cada amostra
    nohup nonpareil -s 1d0SE_1.fasta -T alignment -f fasta -b 1d0SE -t 3 &

üáßüá∑ Ao terminar esse processo, o programa ter√° criado varios
[*outputs*](https://nonpareil.readthedocs.io/en/latest/redundancy.html#output)
por cada amostra. Descarregue os arquivos `.npo`. Use o R, para gr√°ficar
as curvas de satura√ß√£o. A continua√ß√£o se encontra o script.

> üá™üá∏ Al terminar este proceso, el programa habr√° creado varios
> [*outputs*](https://nonpareil.readthedocs.io/en/latest/redundancy.html#output)
> por cada muestra. Descargue los archivos `.npo`. Use R, para gr√°ficar
> las curvas de saturaci√≥n. A continuaci√≥n se encuentra el script.

``` r
library(Nonpareil)
setwd("~/NonPareil")
samples <- read.table('samples.txt', sep='\t', header=TRUE, as.is=TRUE);

attach(samples);
nps <- Nonpareil.set(File, col=Col, labels=Name, 
                     plot.opts=list(plot.observed=FALSE, 
                                    ylim = c(0, 1.05),
                                    legend.opts = FALSE))
  
detach(samples);
summary(nps)
```

Vai obter um gr√°fico com as curvas de satura√ß√£o de cada amostra, como
este:

.center\[<img src="imgs/nonpareil.webp" width="80%">\]

üáßüá∑ As linhas tracejadas <font color='red'> vermelha </font> e
<font color='gray'> cinza </font> representam os *threshold* de 95% e
99% da cobertura m√©dia, respeitivamente. O circulo em cada curva
representa a cobertura atual das amostras, o ideal √© que esteja por cima
do primeiro *threshold*. As curvas tamb√©m apresentam a estima√ß√£o de
quanto esfor√ßo de sequenciamento √© necess√°rio.

> üá™üá∏ Las l√≠neas punteadas <font color='red'> roja </font> y
> <font color='gray'> gris </font> representam los *threshold* de 95% y
> 99% de cobertura promedio, respectivamente. El c√≠rculo en cada curva
> representa la cobertura actual de las muestras, lo ideal es que est√©n
> por encima del primer *threshold*. Las curvas tambi√©n presentan la
> estimaci√≥n de cuanto esfuerzo de secuenciaci√≥n es necesario.

## 3. Montagem dos Metagenomas

### 3.1 MinHash

üáßüá∑ Ap√≥s obter as sequ√™ncias limpas, de boa qualidade, e determinar a
cobertura dos metagenomas, √© poss√≠vel fazer a montagem. No entanto, pode
ser inclu√≠do um passo extra antes da montagem e √© verificar a
similaridade dos datasets para determinar se pode ser usada a abordagem
de *co-assembly*, onde s√£o misturadas as *reads* de v√°rios metagenomas
para gerar os contigs. O programa **Mash** usa uma t√©cnica chamada
redu√ß√£o de dimensionalidad *MinHash* que avalia as dist√¢ncias um a um
entre os datasets.

> üá™üá∏ Despu√©s de obtener las secuencias limpias, de buena calidad, y
> determinar la cobertura de los metagenomas, es posible hacer el
> montaje. Sin embargo, puede ser inclu√≠do un paso extra antes del
> montaje y es verificar la similaridade de los datasets para determinar
> si puede ser usado el abordaje de *co-assembly*, donde son mezcladas
> las *reads* de varios metagenomas para generar los contigs. El
> programa **Mash** usa una t√©cnica llamada reducci√≥n de dimensionalidad
> *MinHash* que evalua las distancias un a un entre los datasets.

    ## Crie uma pasta para o output
    mkdir 04.MinHash

O primeiro paso √© concatenar os reads 1 e 2, e armazenar eles na nova
pasta criada `04.MinHash/`.

**Nota:** Se voc√™ trimou suas sequ√™ncias, deve usar os arquivos gerados
pelo **Trimmomatic** na pasta `03.CleanData`, se pelo contr√°rio suas
sequ√™ncias estavam de boa qualidade e n√£o foi necess√°rio trimar, use os
arquivos originais, que est√£o dentro da pasta `00.RawData`.

> üá™üá∏
>
> **Nota:** Si usted filtr√≥ sus secuencias, debe usar los archivos
> generados por **Trimmomatic** en el directorio `03.CleanData`, si por
> el contrario sus secuencias estaban de buena calidade y no fue
> necesario filtrar, use los archivos originales, que est√°n dentro de la
> carpeta `00.RawData`.

    for i in 03.CleanData/*_1_paired.fq
    do
    BASE=$(basename $i _1_paired.fq)
    cat $i 03.CleanData/${BASE}_2_paired.fastq > 04.MinHash/${BASE}.fq
    done

Then, the samples were sketched to create a combined file, it was used
`mash info` to verify its content, and then estimate pairwise distances:

    mash sketch -o 04.MinHash/reference 04.MinHash/6111_O.fq 04.MinHash/6111_W.fq 04.MinHash/AJ_5.fq 04.MinHash/DQ.fq 04.MinHash/I1.fq 04.MinHash/I2.fq 04.MinHash/K2.fq 04.MinHash/K3.fq 04.MinHash/production_well.fq 04.MinHash/QH.fq 04.MinHash/SB1.fq 04.MinHash/SB2.fq 04.MinHash/jiangsu_W15_metagenome.fq 04.MinHash/jiangsu_W2-71_metagenome.fq 04.MinHash/jiangsu_W9-18_metagenome.fq 04.MinHash/BA1.fq

    #verifiyng
    mash info 04.MinHash/reference.msh

For the last, the distances were calculate using `mash dist` and printed
in the `distancesOutput.tsv` file.

    mash dist 04.MinHash/reference.msh 04.MinHash/reference.msh -p 18 > 04.MinHash/distancesOutputFinal.tsv

### 3.2 Megahit
